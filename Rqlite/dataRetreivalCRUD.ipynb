{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7819f33a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['aws-public-blockchain/v1.0/eth/blocks/date=2015-10-27/part-00000-b4880e90-ba35-432a-aa7c-3fef105d99dc-c000.snappy.parquet']\n",
      "difficulty\n",
      "hash\n",
      "miner\n",
      "nonce\n",
      "number\n",
      "size\n",
      "timestamp\n",
      "total_difficulty\n",
      "base_fee_per_gas\n",
      "gas_limit\n",
      "gas_used\n",
      "extra_data\n",
      "logs_bloom\n",
      "parent_hash\n",
      "state_root\n",
      "receipts_root\n",
      "transactions_root\n",
      "sha3_uncles\n",
      "transaction_count\n",
      "date\n",
      "last_modified\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import s3fs\n",
    "\n",
    "\n",
    "fs = s3fs.S3FileSystem(anon=True)\n",
    "\n",
    "\n",
    "directory_path = 's3://aws-public-blockchain/v1.0/eth/blocks/date=2015-10-27'\n",
    "\n",
    "\n",
    "files = fs.ls(directory_path)\n",
    "\n",
    "parquet_files = [file for file in files if file.endswith('.parquet')]\n",
    "\n",
    "file_path = 's3://' + parquet_files[0]\n",
    "\n",
    "print(parquet_files[:5])\n",
    "\n",
    "with fs.open(file_path, mode='rb') as f:\n",
    "    df = pd.read_parquet(f, engine='pyarrow')\n",
    "\n",
    "\n",
    "for x in df:\n",
    "    print(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c0a7d824",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['aws-public-blockchain/v1.0/eth/blocks/date=2015-07-30/part-00000-32767f69-9150-49ac-9c03-45f34b103c34-c000.snappy.parquet']\n"
     ]
    }
   ],
   "source": [
    "import s3fs\n",
    "\n",
    "\n",
    "fs = s3fs.S3FileSystem(anon=True)\n",
    "\n",
    "\n",
    "directory_path = 's3://aws-public-blockchain/v1.0/eth/blocks/date=2015-07-30/part-00000-32767f69-9150-49ac-9c03-45f34b103c34-c000.snappy.parquet'\n",
    "\n",
    "\n",
    "files = fs.ls(directory_path)\n",
    "\n",
    "\n",
    "parquet_files = [file for file in files]\n",
    "\n",
    "print(parquet_files[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7c149e96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76.7 sdiskio(read_count=87830101, write_count=48867051, read_bytes=3174632250880, write_bytes=2697905180672, read_time=54187482, write_time=2670766) snetio(bytes_sent=3209435121, bytes_recv=10674705813, packets_sent=13271518, packets_recv=19200742, errin=0, errout=0, dropin=11453246114, dropout=0) 14.5 0:00:06.282365\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "import s3fs\n",
    "import pyrqlite.dbapi2 as dbapi2\n",
    "import psutil\n",
    "\n",
    "connection = dbapi2.connect(\n",
    "    host='localhost',\n",
    "    port=4001,\n",
    ")\n",
    "\n",
    "def date_range(start_date, end_date):\n",
    "    for n in range(int((end_date - start_date).days)):\n",
    "        yield start_date + timedelta(n)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    start_date = datetime(2023, 4, 1)  # Start date is today\n",
    "    end_date = start_date + timedelta(days=2)  # End date is 6 months from now\n",
    "\n",
    "    with connection.cursor() as cursor:\n",
    "        cursor.execute('CREATE TABLE IF NOT EXISTS blocks (hsh text)')\n",
    "\n",
    "    ct = 0\n",
    "    memory_percent = 0\n",
    "    disk_io = psutil.disk_io_counters()\n",
    "    network_io = psutil.net_io_counters()\n",
    "    cpu_percent = 0\n",
    "    stTime = datetime.now()\n",
    "    for single_date in date_range(start_date, end_date):\n",
    "        #print(single_date.strftime(\"%Y-%m-%d\"))\n",
    "        dtt = single_date.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "        fs = s3fs.S3FileSystem(anon=True)\n",
    "\n",
    "        directory_path = 's3://aws-public-blockchain/v1.0/eth/blocks/date='+dtt\n",
    "\n",
    "        files = fs.ls(directory_path)\n",
    "\n",
    "        parquet_files = [file for file in files if file.endswith('.parquet')]\n",
    "\n",
    "        file_path = 's3://' + parquet_files[0]\n",
    "\n",
    "        # print(parquet_files[:5])\n",
    "\n",
    "        with fs.open(file_path, mode='rb') as f:\n",
    "            df = pd.read_parquet(f, engine='pyarrow')\n",
    "\n",
    "\n",
    "        for x in df['nonce']:\n",
    "            ct+=1\n",
    "\n",
    "            try:\n",
    "                with connection.cursor() as cursor:\n",
    "                    cursor.executemany('INSERT INTO blocks(hsh) VALUES(?)', seq_of_parameters=((x)))\n",
    "            finally:\n",
    "                connection.close()\n",
    "            if(ct>1000):\n",
    "                break\n",
    "    print(psutil.virtual_memory().percent,psutil.disk_io_counters(),psutil.net_io_counters(),psutil.cpu_percent(interval=1),datetime.now()-stTime)\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
